{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Instance Segmentation for Cell Detection\n",
    "\n",
    "This notebook implements an optimized Mask R-CNN for instance segmentation based on reference code.\n",
    "Key features include:\n",
    "* Mixed precision training with torch.amp for faster computation and reduced memory usage\n",
    "* Memory optimization with explicit CUDA cache clearing\n",
    "* AdamW optimizer and CosineAnnealingLR scheduler for better convergence\n",
    "* Enhanced data augmentation with Albumentations\n",
    "* Support for both resnet50 and resnet50_v2 backbones\n",
    "* Optimized anchor sizes for cell detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.548217Z",
     "iopub.status.busy": "2025-05-07T01:32:55.547615Z",
     "iopub.status.idle": "2025-05-07T01:32:55.553478Z",
     "shell.execute_reply": "2025-05-07T01:32:55.552607Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.548191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1 - Imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import skimage.io as sio\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.detection import (\n",
    "    maskrcnn_resnet50_fpn,\n",
    "    maskrcnn_resnet50_fpn_v2,\n",
    "    MaskRCNN_ResNet50_FPN_Weights,\n",
    "    MaskRCNN_ResNet50_FPN_V2_Weights,\n",
    ")\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from PIL import Image\n",
    "import gc\n",
    "from pycocotools import mask as mask_utils\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.554845Z",
     "iopub.status.busy": "2025-05-07T01:32:55.554593Z",
     "iopub.status.idle": "2025-05-07T01:32:55.575814Z",
     "shell.execute_reply": "2025-05-07T01:32:55.575248Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.554820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2 - Memory Optimization\n",
    "def clear_memory():\n",
    "    \"\"\"Clear memory aggressively.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\n",
    "            f\"CUDA Memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB / {torch.cuda.memory_reserved()/1024**3:.2f}GB\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.577069Z",
     "iopub.status.busy": "2025-05-07T01:32:55.576855Z",
     "iopub.status.idle": "2025-05-07T01:32:55.590268Z",
     "shell.execute_reply": "2025-05-07T01:32:55.589750Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.577053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3 - Utility Functions\n",
    "def decode_maskobj(mask_obj):\n",
    "    \"\"\"\n",
    "    Decode a mask object into a binary mask.\n",
    "    \"\"\"\n",
    "    return mask_utils.decode(mask_obj)\n",
    "\n",
    "\n",
    "def encode_mask(binary_mask):\n",
    "    \"\"\"\n",
    "    Encode a binary mask into a mask object.\n",
    "    \"\"\"\n",
    "    arr = np.asfortranarray(binary_mask).astype(np.uint8)\n",
    "    rle = mask_utils.encode(arr)\n",
    "    rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
    "    return rle\n",
    "\n",
    "\n",
    "def read_maskfile(filepath):\n",
    "    \"\"\"\n",
    "    Read a mask file into a numpy array.\n",
    "    \"\"\"\n",
    "    return sio.imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.591104Z",
     "iopub.status.busy": "2025-05-07T01:32:55.590942Z",
     "iopub.status.idle": "2025-05-07T01:32:55.605152Z",
     "shell.execute_reply": "2025-05-07T01:32:55.604657Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.591091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4 - Dataset\n",
    "class CellInstanceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset for cell instance segmentation.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transform\n",
    "        self.image_dirs = sorted(os.listdir(root_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get an item from the dataset.\n",
    "        \"\"\"\n",
    "        image_name = self.image_dirs[idx]\n",
    "        image_path = os.path.join(self.root_dir, image_name, \"image.tif\")\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        masks = []\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for class_idx in range(1, 5):\n",
    "            class_path = os.path.join(\n",
    "                self.root_dir, image_name, f\"class{class_idx}.tif\"\n",
    "            )\n",
    "            if not os.path.exists(class_path):\n",
    "                continue\n",
    "            try:\n",
    "                class_mask = read_maskfile(class_path)\n",
    "            except Exception:\n",
    "                print(f\"WARN:{class_path}, continue\")\n",
    "                continue\n",
    "            obj_ids = np.unique(class_mask)\n",
    "            obj_ids = obj_ids[obj_ids != 0]\n",
    "            for obj_id in obj_ids:\n",
    "                binary_mask = class_mask == obj_id\n",
    "                pos = np.where(binary_mask)\n",
    "                if pos[0].size == 0 or pos[1].size == 0:\n",
    "                    continue\n",
    "                xmin, xmax = np.min(pos[1]), np.max(pos[1])\n",
    "                ymin, ymax = np.min(pos[0]), np.max(pos[0])\n",
    "                if xmax <= xmin or ymax <= ymin:\n",
    "                    print(f\"WARN illegal box in {image_name} id={obj_id}\")\n",
    "                    continue\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                masks.append(binary_mask)\n",
    "                labels.append(class_idx)\n",
    "        if len(boxes) == 0:\n",
    "            # Handle empty cases\n",
    "            H, W = image.height, image.width\n",
    "            masks = torch.zeros((0, H, W), dtype=torch.uint8)\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            masks = torch.as_tensor(np.stack(masks).astype(np.uint8), dtype=torch.uint8)\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "            \"image_id\": torch.tensor([idx]),\n",
    "        }\n",
    "        # Apply transforms\n",
    "        if self.transforms is not None:\n",
    "            image, target = self.transforms(image, target)\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the length of the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.image_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.606732Z",
     "iopub.status.busy": "2025-05-07T01:32:55.606566Z",
     "iopub.status.idle": "2025-05-07T01:32:55.716983Z",
     "shell.execute_reply": "2025-05-07T01:32:55.716497Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.606719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5 - Data Transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "\n",
    "class MaskRCNNTransforms:\n",
    "    \"\"\"\n",
    "    A class for data transforms for Mask R-CNN.\n",
    "    \"\"\"\n",
    "    def __init__(self, is_train=True):\n",
    "        \"\"\"\n",
    "        Initialize the transforms.\n",
    "        \"\"\"\n",
    "        if is_train:\n",
    "            self.transforms = T.Compose(\n",
    "                [\n",
    "                    T.RandomHorizontalFlip(p=0.5),\n",
    "                    T.RandomVerticalFlip(p=0.5),\n",
    "                    T.RandomApply([T.ElasticTransform(alpha=30, sigma=12)], p=0.3),\n",
    "                    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transforms = T.Compose(\n",
    "                [\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        \"\"\"\n",
    "        Apply the transforms to the image and target.\n",
    "        \"\"\"\n",
    "        image, target = self.transforms(image, target)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.717931Z",
     "iopub.status.busy": "2025-05-07T01:32:55.717663Z",
     "iopub.status.idle": "2025-05-07T01:32:55.721440Z",
     "shell.execute_reply": "2025-05-07T01:32:55.720749Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.717910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6 - Collate Function\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function for the dataset.\n",
    "    \"\"\"\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.723176Z",
     "iopub.status.busy": "2025-05-07T01:32:55.722990Z",
     "iopub.status.idle": "2025-05-07T01:32:55.736955Z",
     "shell.execute_reply": "2025-05-07T01:32:55.736382Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.723162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7 - Model\n",
    "def get_model(num_classes=5, model_type=\"resnet50_v2\", min_size=512, max_size=512):\n",
    "    \"\"\"\n",
    "    Create a Mask R-CNN model with performance improvements.\n",
    "    \"\"\"\n",
    "    # Load specified backbone with pretrained weights\n",
    "    try:\n",
    "        if model_type == \"resnet50\":\n",
    "            weights = MaskRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "            model = maskrcnn_resnet50_fpn(\n",
    "                weights=weights, progress=True, min_size=min_size, max_size=max_size\n",
    "            )\n",
    "        elif model_type == \"resnet50_v2\":\n",
    "            weights = MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "            model = maskrcnn_resnet50_fpn_v2(\n",
    "                weights=weights, progress=True, min_size=min_size, max_size=max_size\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unknown model_type '{model_type}', expected 'resnet50' or 'resnet50_v2'\"\n",
    "            )\n",
    "\n",
    "        # Use smaller anchor sizes optimized for cell detection\n",
    "        if hasattr(model, \"rpn\") and hasattr(model.rpn, \"anchor_generator\"):\n",
    "            # Smaller anchor sizes for detecting tiny cell objects\n",
    "            model.rpn.anchor_generator.sizes = tuple(\n",
    "                [(8,), (16,), (32,), (64,), (128,)]\n",
    "            )\n",
    "\n",
    "            # More aspect ratios for better coverage\n",
    "            model.rpn.anchor_generator.aspect_ratios = ((0.5, 1.0, 2.0),) * len(\n",
    "                model.rpn.anchor_generator.sizes\n",
    "            )\n",
    "\n",
    "        # Replace the classification head\n",
    "        in_features_box = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features_box, num_classes)\n",
    "\n",
    "        # Replace the mask prediction head\n",
    "        in_channels_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "        model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "            in_channels_mask, 256, num_classes\n",
    "        )\n",
    "\n",
    "        # Adjust proposals per image and NMS settings\n",
    "        if hasattr(model, \"roi_heads\"):\n",
    "            model.roi_heads.detections_per_img = 200  # Increased from 100\n",
    "            if hasattr(model.roi_heads, \"nms_thresh\"):\n",
    "                model.roi_heads.nms_thresh = 0.3  # Lower NMS threshold\n",
    "            model.roi_heads.score_thresh = 0.01  # Lower score threshold\n",
    "\n",
    "        clear_memory()\n",
    "        return model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model: {e}\")\n",
    "        # In case of error, try with more conservative memory settings\n",
    "        clear_memory()\n",
    "        if model_type == \"resnet50\":\n",
    "            weights = MaskRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "            model = maskrcnn_resnet50_fpn(\n",
    "                weights=weights, min_size=min_size // 2, max_size=max_size // 2\n",
    "            )\n",
    "        else:\n",
    "            weights = MaskRCNN_ResNet50_FPN_Weights.DEFAULT  # Fallback to resnet50\n",
    "            model = maskrcnn_resnet50_fpn(\n",
    "                weights=weights, min_size=min_size // 2, max_size=max_size // 2\n",
    "            )\n",
    "\n",
    "        # Basic required model updates\n",
    "        in_features_box = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features_box, num_classes)\n",
    "\n",
    "        # Reduce proposals to minimum\n",
    "        model.roi_heads.detections_per_img = 50\n",
    "\n",
    "        clear_memory()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.737785Z",
     "iopub.status.busy": "2025-05-07T01:32:55.737545Z",
     "iopub.status.idle": "2025-05-07T01:32:55.756464Z",
     "shell.execute_reply": "2025-05-07T01:32:55.755898Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.737745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8 - Training Function with Mixed Precision\n",
    "def train_one_epoch(model, optimizer, data_loader, device, mixed_precision=True):\n",
    "    \"\"\"\n",
    "    Train one epoch of the model.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    # Mixed precision setup\n",
    "    scaler = torch.amp.GradScaler(\"cuda\") if mixed_precision else None\n",
    "    for batch_idx, (images, targets) in enumerate(tqdm(data_loader)):\n",
    "        try:\n",
    "            # Move data to device\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass with or without mixed precision\n",
    "            if mixed_precision:\n",
    "                with torch.amp.autocast(\"cuda\"):\n",
    "                    loss_dict = model(images, targets)\n",
    "                    losses = sum(loss for loss in loss_dict.values())\n",
    "                # Skip batches with infinite or NaN losses\n",
    "                if not torch.isfinite(losses):\n",
    "                    print(f\"[Error Batch {batch_idx}] infinite loss: {losses}\")\n",
    "                    continue\n",
    "                # Mixed precision backward and optimizer step\n",
    "                scaler.scale(losses).backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Standard training\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "                # Skip batches with infinite or NaN losses\n",
    "                if not torch.isfinite(losses):\n",
    "                    print(f\"[Error Batch {batch_idx}] infinite loss: {losses}\")\n",
    "                    continue\n",
    "                losses.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "                optimizer.step()\n",
    "            # Calculate mAP metrics\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                preds = model(images)\n",
    "            model.train()\n",
    "            preds_cpu = [\n",
    "                {\n",
    "                    \"boxes\": p[\"boxes\"].cpu(),\n",
    "                    \"scores\": p[\"scores\"].cpu(),\n",
    "                    \"labels\": p[\"labels\"].cpu(),\n",
    "                }\n",
    "                for p in preds\n",
    "            ]\n",
    "            gts_cpu = [\n",
    "                {\"boxes\": t[\"boxes\"].cpu(), \"labels\": t[\"labels\"].cpu()}\n",
    "                for t in targets\n",
    "            ]\n",
    "            metric.update(preds_cpu, gts_cpu)\n",
    "            total_loss += losses.item()\n",
    "            num_batches += 1\n",
    "            # Periodically clear memory\n",
    "            if batch_idx % 5 == 0:\n",
    "                clear_memory()\n",
    "        except Exception as e:\n",
    "            print(f\"[Error in Batch {batch_idx}]: {e}\")\n",
    "            clear_memory()\n",
    "            continue\n",
    "    avg_loss = total_loss / max(num_batches, 1)\n",
    "    stats = metric.compute()\n",
    "    map_score = stats[\"map\"].item()\n",
    "    map50_score = stats[\"map_50\"].item()\n",
    "    print(\n",
    "        f\"\\n[Epoch Summary] Loss: {avg_loss:.4f} | mAP: {map_score:.4f} | mAP@50: {map50_score:.4f}\\n\"\n",
    "    )\n",
    "    return avg_loss, map_score, map50_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.757435Z",
     "iopub.status.busy": "2025-05-07T01:32:55.757182Z",
     "iopub.status.idle": "2025-05-07T01:32:55.775187Z",
     "shell.execute_reply": "2025-05-07T01:32:55.774515Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.757413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 9 - Validation Function\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc=\"Validating\"):\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                preds = model(images)\n",
    "            preds_cpu = [\n",
    "                {\n",
    "                    \"boxes\": p[\"boxes\"].cpu(),\n",
    "                    \"scores\": p[\"scores\"].cpu(),\n",
    "                    \"labels\": p[\"labels\"].cpu(),\n",
    "                }\n",
    "                for p in preds\n",
    "            ]\n",
    "            gts_cpu = [\n",
    "                {\"boxes\": t[\"boxes\"].cpu(), \"labels\": t[\"labels\"].cpu()}\n",
    "                for t in targets\n",
    "            ]\n",
    "            metric.update(preds_cpu, gts_cpu)\n",
    "    stats = metric.compute()\n",
    "    map_score = stats[\"map\"].item()\n",
    "    map50_score = stats[\"map_50\"].item()\n",
    "    print(f\"Validation: mAP: {map_score:.4f} | mAP@50: {map50_score:.4f}\")\n",
    "    return map_score, map50_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.776070Z",
     "iopub.status.busy": "2025-05-07T01:32:55.775830Z",
     "iopub.status.idle": "2025-05-07T01:32:55.796037Z",
     "shell.execute_reply": "2025-05-07T01:32:55.795338Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.776050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 10 - Inference and Submission\n",
    "def inference(\n",
    "    model,\n",
    "    test_dir,\n",
    "    output_json,\n",
    "    image_id_map,\n",
    "    confidence_threshold=0.1,\n",
    "    mask_threshold=0.6,\n",
    "):\n",
    "    \"\"\"\n",
    "    Inference and submission.\n",
    "    \"\"\"\n",
    "    clear_memory()\n",
    "    model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for image_file in tqdm(os.listdir(test_dir)):\n",
    "            try:\n",
    "                # Load and preprocess image\n",
    "                image_path = os.path.join(test_dir, image_file)\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "                # Convert to tensor and normalize\n",
    "                image_tensor = F.to_tensor(image).unsqueeze(0)\n",
    "                image_tensor = F.normalize(\n",
    "                    image_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ).cuda()\n",
    "                # Run inference with mixed precision\n",
    "                with torch.amp.autocast(\"cuda\"):\n",
    "                    output = model(image_tensor)[0]\n",
    "                # Filter results based on confidence threshold (match ref3 implementation)\n",
    "                keep = output[\"scores\"] >= confidence_threshold\n",
    "                scores = output[\"scores\"][keep].cpu()\n",
    "                labels = output[\"labels\"][keep].cpu()\n",
    "                masks = output[\"masks\"][keep, 0].cpu()  # (N,H,W) already squeezed\n",
    "                boxes = output[\"boxes\"][keep].cpu()  # (N,4) x1,y1,x2,y2\n",
    "                # Process results\n",
    "                for score, mask, label, box in zip(scores, masks, labels, boxes):\n",
    "                    # Get bounding box coordinates and convert to xywh format\n",
    "                    x1, y1, x2, y2 = box.tolist()\n",
    "                    width = max(0.0, x2 - x1)\n",
    "                    height = max(0.0, y2 - y1)\n",
    "                    bbox = [x1, y1, width, height]\n",
    "                    # Skip invalid boxes\n",
    "                    if width <= 1 or height <= 1:\n",
    "                        continue\n",
    "                    # Binarize mask and encode as RLE\n",
    "                    mask_bin = (mask > mask_threshold).numpy().astype(np.uint8)\n",
    "\n",
    "                    # Skip empty masks\n",
    "                    if mask_bin.sum() == 0:\n",
    "                        continue\n",
    "                    # Encode mask to RLE format\n",
    "                    try:\n",
    "                        rle = encode_mask(mask_bin)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error encoding mask: {e}\")\n",
    "                        continue\n",
    "                    # Get category ID and ensure it's valid (1-4)\n",
    "                    category_id = int(label)\n",
    "                    if category_id < 1 or category_id > 4:\n",
    "                        print(f\"Warning: Invalid category_id {category_id}, skipping\")\n",
    "                        continue\n",
    "                    # Add result to list\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"image_id\": image_id_map[image_file],\n",
    "                            \"bbox\": [float(v) for v in bbox],\n",
    "                            \"score\": float(score),\n",
    "                            \"category_id\": category_id,\n",
    "                            \"segmentation\": {\n",
    "                                \"size\": list(mask_bin.shape),\n",
    "                                \"counts\": rle[\"counts\"],\n",
    "                            },\n",
    "                        }\n",
    "                    )\n",
    "                # Clear memory after processing each image\n",
    "                if len(os.listdir(test_dir)) > 50 and len(results) % 10 == 0:\n",
    "                    clear_memory()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_file}: {e}\")\n",
    "                continue\n",
    "    # Print statistics about results\n",
    "    print(\n",
    "        f\"Generated {len(results)} predictions across {len(os.listdir(test_dir))} images\"\n",
    "    )\n",
    "    # Count predictions by category\n",
    "    categories = {}\n",
    "    for r in results:\n",
    "        cat = r[\"category_id\"]\n",
    "        categories[cat] = categories.get(cat, 0) + 1\n",
    "    print(\"Predictions by category:\")\n",
    "    for cat, count in categories.items():\n",
    "        print(f\"  Category {cat}: {count} predictions\")\n",
    "    # Calculate average score\n",
    "    avg_score = sum(r[\"score\"] for r in results) / max(len(results), 1)\n",
    "    print(f\"Average confidence score: {avg_score:.4f}\")\n",
    "    # Save results\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(results, f)\n",
    "    print(f\"Saved {len(results)} predictions to {output_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:32:55.797015Z",
     "iopub.status.busy": "2025-05-07T01:32:55.796802Z",
     "iopub.status.idle": "2025-05-07T01:32:55.817596Z",
     "shell.execute_reply": "2025-05-07T01:32:55.816896Z",
     "shell.execute_reply.started": "2025-05-07T01:32:55.797000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 11 - Main (Training)\n",
    "def main_train():\n",
    "    \"\"\"\n",
    "    Main training function.\n",
    "    \"\"\"\n",
    "    train_root = \"/kaggle/input/dataset/train\"\n",
    "    model_path = \"/kaggle/working/maskrcnn_model.pth\"\n",
    "    # Set up training parameters\n",
    "    model_type = \"resnet50_v2\"  # Use the more powerful backbone\n",
    "    num_epochs = 50\n",
    "    batch_size = 2  # Reduced batch size to prevent OOM\n",
    "    learning_rate = 1e-4\n",
    "    use_mixed_precision = False  # Enable mixed precision training\n",
    "    # Set up device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    # Initialize transforms and datasets\n",
    "    train_transform = MaskRCNNTransforms(is_train=True)\n",
    "    val_transform = MaskRCNNTransforms(is_train=False)\n",
    "    # Create model with performance improvements\n",
    "    model = get_model(num_classes=5, model_type=model_type)\n",
    "    model.to(device)\n",
    "    # Check if model already exists\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print(\"Model already trained, loaded checkpoint.\")\n",
    "        return model\n",
    "    # Set up training dataset and data loader\n",
    "    train_dataset = CellInstanceDataset(train_root, transform=train_transform)\n",
    "    # Split dataset into train and validation\n",
    "    train_size = int(0.9 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_ds, val_ds = torch.utils.data.random_split(\n",
    "        train_dataset,\n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42),\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    # Set up optimizer with weight decay\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = AdamW(params, lr=learning_rate, weight_decay=1e-4)\n",
    "    # Learning rate scheduler\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    # Training loop\n",
    "    best_map = 0.0\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"--- Epoch {epoch + 1}/{num_epochs} ---\")\n",
    "        epoch_start = time.time()\n",
    "        # Train one epoch\n",
    "        train_loss, train_map, train_map50 = train_one_epoch(\n",
    "            model, optimizer, train_loader, device, mixed_precision=use_mixed_precision\n",
    "        )\n",
    "        # Validate\n",
    "        val_map, val_map50 = validate(model, val_loader, device)\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        # Save model if it's the best so far\n",
    "        map_sum = val_map + val_map50\n",
    "        if map_sum > best_map:\n",
    "            best_map = map_sum\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\n",
    "                f\"New best model saved with mAP {val_map:.4f} / mAP@50 {val_map50:.4f}\"\n",
    "            )\n",
    "        # Report progress\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(\n",
    "            f\"Epoch completed in {epoch_time:.2f}s. \"\n",
    "            f\"Current learning rate: {current_lr:.2e}\"\n",
    "        )\n",
    "        # Clear memory between epochs\n",
    "        clear_memory()\n",
    "    # Report training time\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time/60:.2f} minutes.\")\n",
    "    print(f\"Best mAP sum: {best_map:.4f}\")\n",
    "    print(f\"Final model saved to {model_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T06:18:23.042312Z",
     "iopub.status.busy": "2025-05-07T06:18:23.041454Z",
     "iopub.status.idle": "2025-05-07T06:18:23.057091Z",
     "shell.execute_reply": "2025-05-07T06:18:23.056446Z",
     "shell.execute_reply.started": "2025-05-07T06:18:23.042283Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 12 - Visualization Functions\n",
    "def ensure_dir(directory):\n",
    "    \"\"\"Create directory if it doesn't exist.\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "def visualize_predictions(\n",
    "    image_path,\n",
    "    results,\n",
    "    image_id_map,\n",
    "    num_samples=5,\n",
    "    figsize=(15, 10),\n",
    "    save_dir=\"visualizations\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize instance segmentation predictions on images.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the test images directory\n",
    "        results: List of prediction results from inference\n",
    "        image_id_map: Dictionary mapping image filenames to IDs\n",
    "        num_samples: Number of random samples to visualize\n",
    "        figsize: Figure size for the plot\n",
    "        save_dir: Directory to save the visualizations\n",
    "    \"\"\"\n",
    "    # Create save directory\n",
    "    ensure_dir(save_dir)\n",
    "    # Group results by image_id\n",
    "    results_by_image = {}\n",
    "    for result in results:\n",
    "        image_id = result[\"image_id\"]\n",
    "        if image_id not in results_by_image:\n",
    "            results_by_image[image_id] = []\n",
    "        results_by_image[image_id].append(result)\n",
    "    # Select random samples\n",
    "    sample_images = random.sample(\n",
    "        list(\n",
    "            results_by_image.keys()),\n",
    "            min(num_samples, \n",
    "            len(results_by_image)))\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=figsize)\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    # Define colors for different categories (RGB values)\n",
    "    colors = [\n",
    "        (1.0, 0.0, 0.0),  # Red\n",
    "        (0.0, 1.0, 0.0),  # Green\n",
    "        (0.0, 0.0, 1.0),  # Blue\n",
    "        (1.0, 1.0, 0.0),  # Yellow\n",
    "    ]\n",
    "    for idx, image_id in enumerate(sample_images):\n",
    "        # Find the corresponding image file\n",
    "        image_file = None\n",
    "        for file_name, id in image_id_map.items():\n",
    "            if id == image_id:\n",
    "                image_file = file_name\n",
    "                break\n",
    "        if image_file is None:\n",
    "            continue\n",
    "        # Load and display original image\n",
    "        img_path = os.path.join(image_path, image_file)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        axes[idx, 0].imshow(img)\n",
    "        axes[idx, 0].set_title(f\"Original Image: {image_file}\")\n",
    "        axes[idx, 0].axis(\"off\")\n",
    "        # Display predictions\n",
    "        axes[idx, 1].imshow(img)\n",
    "        predictions = results_by_image[image_id]\n",
    "        # Create a mask overlay\n",
    "        mask_overlay = np.zeros(\n",
    "            (img.height, img.width, 4), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        for pred in predictions:\n",
    "            # Get prediction details\n",
    "            bbox = pred[\"bbox\"]\n",
    "            category_id = pred[\"category_id\"]\n",
    "            score = pred[\"score\"]\n",
    "            # Get color for this category\n",
    "            color = colors[category_id - 1]\n",
    "            # Draw bounding box\n",
    "            rect = patches.Rectangle(\n",
    "                (bbox[0], bbox[1]),\n",
    "                bbox[2],\n",
    "                bbox[3],\n",
    "                linewidth=2,\n",
    "                edgecolor=color,\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            axes[idx, 1].add_patch(rect)\n",
    "            # Add label\n",
    "            axes[idx, 1].text(\n",
    "                bbox[0],\n",
    "                bbox[1] - 5,\n",
    "                f\"Class {category_id} ({score:.2f})\",\n",
    "                color=color,\n",
    "                fontsize=8,\n",
    "                bbox=dict(facecolor=\"white\", alpha=0.7),\n",
    "            )\n",
    "            # Decode and overlay mask\n",
    "            if \"segmentation\" in pred:\n",
    "                mask = decode_maskobj(pred[\"segmentation\"])\n",
    "                # Add alpha channel to color\n",
    "                color_with_alpha = [*color, 0.3]\n",
    "                mask_overlay[mask > 0] = color_with_alpha\n",
    "        # Overlay masks\n",
    "        axes[idx, 1].imshow(mask_overlay)\n",
    "        axes[idx, 1].set_title(f\"Predictions: {image_file}\")\n",
    "        axes[idx, 1].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_path = os.path.join(save_dir, f\"predictions_{timestamp}.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Saved predictions visualization to: {save_path}\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_training_metrics(\n",
    "    train_losses, train_maps, val_maps, figsize=(15, 5), \n",
    "    save_dir=\"visualizations\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot training metrics over epochs.\n",
    "    Args:\n",
    "        train_losses: List of training losses\n",
    "        train_maps: List of training mAP scores\n",
    "        val_maps: List of validation mAP scores\n",
    "        figsize: Figure size for the plot\n",
    "        save_dir: Directory to save the plots\n",
    "    \"\"\"\n",
    "    # Create save directory\n",
    "    ensure_dir(save_dir)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "    # Plot training loss\n",
    "    ax1.plot(train_losses, label=\"Training Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.set_title(\"Training Loss over Epochs\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    # Plot mAP scores\n",
    "    ax2.plot(train_maps, label=\"Training mAP\")\n",
    "    ax2.plot(val_maps, label=\"Validation mAP\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"mAP\")\n",
    "    ax2.set_title(\"mAP Scores over Epochs\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_path = os.path.join(save_dir, f\"training_metrics_{timestamp}.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Saved training metrics plot to: {save_path}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T06:18:29.647579Z",
     "iopub.status.busy": "2025-05-07T06:18:29.646977Z",
     "iopub.status.idle": "2025-05-07T06:18:29.656334Z",
     "shell.execute_reply": "2025-05-07T06:18:29.655565Z",
     "shell.execute_reply.started": "2025-05-07T06:18:29.647554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 13 - Main (Testing/Inference)\n",
    "def main_test(model=None):\n",
    "    # Load paths\n",
    "    test_root = \"/kaggle/input/dataset/test_release\"\n",
    "    image_id_map_path = \"/kaggle/input/dataset/test_image_name_to_ids.json\"\n",
    "    model_path = \"/kaggle/working/maskrcnn_model.pth\"\n",
    "    # Create visualization directory\n",
    "    vis_dir = \"/kaggle/working/visualizations\"\n",
    "    ensure_dir(vis_dir)\n",
    "    # Load image ID mapping\n",
    "    with open(image_id_map_path, \"r\") as f:\n",
    "        image_id_map = json.load(f)\n",
    "        if isinstance(image_id_map, list):\n",
    "            image_id_map = {item[\"file_name\"]: item[\"id\"] for item in image_id_map}\n",
    "        print(f\"Loaded image ID mapping with {len(image_id_map)} entries\")\n",
    "    # Set up device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Load model if not provided\n",
    "    if model is None:\n",
    "        model_type = \"resnet50_v2\"  # Use the more powerful backbone for inference\n",
    "        model = get_model(num_classes=5, model_type=model_type)\n",
    "        model.to(device)\n",
    "        if os.path.exists(model_path):\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            print(\"Loaded pretrained model for inference.\")\n",
    "        else:\n",
    "            print(\"No trained model found. Run training first!\")\n",
    "            return\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Lower the score threshold for the model's ROI heads\n",
    "    if hasattr(model, \"roi_heads\"):\n",
    "        original_threshold = model.roi_heads.score_thresh\n",
    "        model.roi_heads.score_thresh = 0.1\n",
    "        print(f\"Set model ROI score threshold to {model.roi_heads.score_thresh}\")\n",
    "    # Run inference with the same thresholds as in ref3/infer.sh\n",
    "    inference(\n",
    "        model,\n",
    "        test_root,\n",
    "        \"test-results.json\",\n",
    "        image_id_map,\n",
    "        confidence_threshold=0.5,\n",
    "        mask_threshold=0.6,\n",
    "    )\n",
    "    print(\"Inference complete. Results saved to test-results.json\")\n",
    "    # Load results for visualization\n",
    "    with open(\"test-results.json\", \"r\") as f:\n",
    "        results = json.load(f)\n",
    "    # Visualize predictions\n",
    "    print(\"\\nVisualizing predictions...\")\n",
    "    visualize_predictions(\n",
    "        test_root, results, image_id_map, num_samples=5, save_dir=vis_dir\n",
    "    )\n",
    "    # Print some statistics about the predictions\n",
    "    print(\"\\nPrediction Statistics:\")\n",
    "    scores = [r[\"score\"] for r in results]\n",
    "    print(f\"Average confidence score: {np.mean(scores):.4f}\")\n",
    "    print(f\"Min confidence score: {np.min(scores):.4f}\")\n",
    "    print(f\"Max confidence score: {np.max(scores):.4f}\")\n",
    "    # Count predictions by category\n",
    "    categories = {}\n",
    "    for r in results:\n",
    "        cat = r[\"category_id\"]\n",
    "        categories[cat] = categories.get(cat, 0) + 1\n",
    "    print(\"\\nPredictions by category:\")\n",
    "    for cat, count in sorted(categories.items()):\n",
    "        print(f\"  Category {cat}: {count} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T06:18:40.974599Z",
     "iopub.status.busy": "2025-05-07T06:18:40.974010Z",
     "iopub.status.idle": "2025-05-07T06:19:06.303668Z",
     "shell.execute_reply": "2025-05-07T06:19:06.303028Z",
     "shell.execute_reply.started": "2025-05-07T06:18:40.974573Z"
    }
   },
   "outputs": [],
   "source": [
    "main_test(model)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7282990,
     "sourceId": 11611125,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
